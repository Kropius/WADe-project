<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title> RAT - Technical report </title>
    <link rel="stylesheet" href="TechnicalReport.css">
</head>

<body>
    <article>
        <header>
            <h1 style="font-size:250% !important;">
                RAT - Technical report
            </h1>
            <section typeof=sa:AuthorList>
                <h2 style="font-size:150% !important;">
                    Developed by:
                </h2>
                <ul style="list-style-type : none;">
                    <li typeOf="sa:ContributorRole" property="schema:Author">
                        <span typeof="schema:Person">
                            <span property="schema:name">Cioată Matei-Alexandru</span>
                        </span>
                    </li>
                    <li typeOf="sa:ContributorRole" property="schema:Author">
                        <span typeof="schema:Person">
                            <span property="schema:name">Lipan Radu-Matei</span>
                        </span>
                    </li>
                    <li typeOf="sa:ContributorRole" property="schema:Author">
                        <span typeof="schema:Person">
                            <span property="schema:name">Rezmeriță Mihnea-Ioan</span>
                        </span>
                    </li>
                </ul>
            </section>
        </header>
        <section>
            <h2> 1. Description </h2>
            <p> &emsp; &emsp;
                The application Rest Api Interactive Tool(known as RAT) is a web tool that uses natural language
                constructs to interact with different REST APIs based on their OpenApi
                documentation. With this, a human-like(text based/voice) interaction with the given APIs will be
                possible. The end user will have the possibility to select an API, from a predefined list, or upload 
                the OpenAPI specification of one. He will be able to interact in a natural manner with the API using
                the web interface of the application.
            </p>
            <p>
                &emsp; &emsp; The application will be able to determine valid routes, with valid request bodies or even
                query parameters, according to the selected RestApi, based on the user's commands in natural language.
            </p>
        </section>
        <section>
            <h2>2. Usecase</h2>
            <figure typeOf="sa:image">
                    <img src="../ArchitectureAndDesign/use-case.jpg" alt="Usecase diagram">
                    <figcaption style="text-align: center;">Fig. 1: Usecase diagram</figcaption>
            </figure>
            <p>
                &emsp; &emsp; The above diagram displays the possible ways the user can interact with the application:
            </p>
            <ul>
                <li><em>Uploads a valid OpenApi documentation:</em> The user can upload an OpenApi documentation that will
                    be parsed and saved on the server side to facilitate future queries in natural language.</li>
                <li><em>Choose an available API: </em> The user will select a certain API from the given list of previously
                    added APIs. The application will make the future translation based on this API.</li>
                <li><em>Types a request: </em> The user can type any sentance he wants and the application will try to map
                    it to a valid <em>route</em>, <em>body</em>, <em>Rest verb</em> and <em>parameters</em> </li>
                <li><em>Uses speech recognition in order to send the request: </em> Similar to <em>Types a request</em> but
                    this time, the user speak aloud his request and the application will transform the recording to text and
                    then return a valid <em>route</em>, <em>body</em>, <em>Rest verb</em> and <em>parameters</em> </li>
            </ul>
        </section>
        <section>
            <h2>3. Architecture</h2>
                <figure typeOf="sa:image">
                    <img src="../ArchitectureAndDesign/rat-overview.png" alt="App's Architecture">
                    <figcaption style="text-align: center;">Fig. 2: App's Architecture</figcaption>
            </figure>
            <p> &emsp; &emsp;
                The whole backend application will be built using <a href="https://cloud.google.com/">Google Cloud Services</a>.
            It was chosen over other cloud services providers because of the generous <a href="https://cloud.google.com/free">free tier</a> provided.
            </p>
            <p> &emsp; &emsp;
                The main computation provider will be <a href="https://cloud.google.com/functions">Google Cloud Functions</a>. The FaaS approach will 
            help us better decouple the logic between our endpoints while keeping costs at a minimum with the "pay as you go" approach of such services.
            We will be able to choose our programming language based on what that function needs to do (in example, python for NLP, NodeJs for CRUD operations
            on our noSql Database) without needing to setup a separate server for that language as well. One main drawback of this approach would be the 
            "cold starts" that appear on log traffic but there are workarounds for that: some light weight languages and frameworks like NodeJs have a way smaller
            cold starts than others like Java and if that's not enough we can always put in place a warmup system. In order to provide a common interface and url
            for all our functions, we will be using <a href="https://cloud.google.com/api-gateway">Google Cloud API Gateway</a>. This way we have a single point where
            we need to setup the authentication for our api and where we can check that everything specified in <a href="../OpenApi/openapi.yaml">our OpenAPI specification</a>
            is indeed followed accordingly.
            </p>
            <p> &emsp; &emsp;
                For storage we will be using <a href="https://cloud.google.com/firestore">Firestore</a>, Google Cloud's main NoSQL solution. We'll be going with noSql
            because we have only one type of entities: apis; and we don't have any complex relationships between entities besides some child-parent relationships
            (api-endpoints-attributes). Also, the change of one child doesn't need to be reflected in all of its other appearences so we don't have a need for normalisation.
            </p>
            <p> &emsp; &emsp;
                We will also be using <a href="https://cloud.google.com/natural-language">Google Cloud Natural Language Processing API</a> and 
            <a href="https://cloud.google.com/speech-to-text">Google Cloud Speech-To-Text API</a> as described in <em>"4. Natural Language Processing"</em>
            and <em>4.1 Optional Preprocessing: Speech recognition</em> respectively.
            </p>
            <p> &emsp; &emsp;
                We need only one page in our frontend app, so using SPA framework is an intuitive solution. We will be using Angular or React for that. Because of thei nature,
            SPAs don't need computaion power for hosting so we are fine with using <a href="https://cloud.google.com/storage">Google Cloud Storage</a> in order to provide our
            single <em>index.html</em> file and its dependencies to client browsers.
            </p>
        </section>
        <section>
            <h2>4. Natural Language Processing</h2>
            <p> &emsp; &emsp;
				In order to facilitate text/voice interaction with our application, we decided to use Google Cloud’s Natural Language AI. 
				This service will help with the sentence analysis and parsing, providing useful data that takes the program one step closer 
				to an output in the form of a valid REST request. 
			</p>
			<p>
				&emsp; &emsp;
				“The Cloud Natural Language API provides natural language understanding technologies to developers, including sentiment 
				analysis, entity analysis, entity sentiment analysis, content classification, and syntax analysis.” (1)
			</p>
			<p>
				&emsp; &emsp;
				The most useful functionality in our case is the syntax analysis, as it inspects the structure of the language. In other 
				words, when the user writes a command in the form of a sentence and passes it to the Natural Language API, it is broken 
				into tokens (words) which are returned along with detailed linguistic information: part of speech, morphology and most 
				importantly, dependency tree. 
			</p>
			<p>
				&emsp; &emsp;
				All of this data represents the input for our REST request builder algorithm. The main idea of it is to build a syntactic 
				tree using the information from Natural Language API and then to match the key words from the nodes with the input API 
				specification. In order to form the syntactic tree from the sentence, we need to follow a set of rules:
			</p>
			<ul>
                <li>
					<em>Identifying the root: </em> it is usually a verb at imperative mood (also marked with root label by the Natural 
					Language API). For example, this verb can be “Show”, “Create” etc.. Unfortunately, this is not always the case as we can 
					have expressions like “I want to add …” where “want” is the root verb of the sentence, but “add” is the REST correspondent 
					for the POST operation. Therefore, the root of the syntactic tree will be the verb that matches any HTTP operation the most;
				</li>
                <li>
					<em>Identifying the main entity: </em> this step is trivial as the Natural Language API provides a direct dependency 
					between the verb defining the REST operation and the main entity;
				</li>
                <li>
					<em>Identifying the attribute names of an entity: </em>  as we descend the dependency tree of a main entity, all of 
					the nouns represent attribute names (if multiple attributes of the same entity are specified, they will appear on 
					successive levels in the dependency tree);
				</li>
                <li>
					<em>Identifying the attribute values: </em>  Natural Language API provides a direct dependency between nouns and 
					corresponding adjectives, numerals and determiners;
				</li>
				<li>
					Parts of speech other than nouns, adjectives, numerals, verbs and determiners will be ignored in the tree building process.
				</li>
            </ul>
			<p>
				&emsp; &emsp;
				The syntactic tree is getting close to forming the valid REST request as it offers information about the HTTP verb and 
				the main entities along with their attribute names and values, but there is one more major problem: some words might be 
				unknown. Let’s take an example: “Show me all cats with blue colouring.”. The final tree will have the following form:
			</p>
			<figure typeOf="sa:image" class="ignore-margins">
                <img src="../ArchitectureAndDesign/rat-nlp-algorithm-example.png" alt="RAT Syntactic tree example" style="width:40%">
                <figcaption style="text-align: center;">Fig. 3: RAT - Syntactic tree example</figcaption>
            </figure>
			<p>
				&emsp; &emsp;
				The match for the above request would be GET on path /cats?color=blue. Even though “colouring” resembles “color”, we need a
				way to match these words. A very good candidate for this would be Word2Vec or any similar tool.
			</p>
			<p>
				&emsp; &emsp;
				“Word2vec is a technique for natural language processing published in 2013. The word2vec algorithm uses a neural network 
				model to learn word associations from a large corpus of text.” (2) This tool offers the possibility to easily detect 
				synonyms or related words, based on a score. The root verb will always be detected this way. In the beginning of the 
				algorithm, we can set a default pair for each HTTP verb (for example: GET - “Provide”, POST - “Create”, PUT - “Replace”, 
				DELETE - “Delete”, PATCH - “Update”). Using Word2Vec, “Show” will be matched with “Provide” with a high score, therefore 
				matching with GET.
			</p>
			<p>
				&emsp; &emsp;
				As an observation from the above example, “all” has been kept in the syntactic tree. It is a determiner and it communicates 
				that all cats should be retrieved. Another valid determiner would be “a” in which case a single cat should be retrieved 
				(the first one or a random one). There are also examples that should be ignored: “the”, “this”, “few” etc..
			</p>
			<p>
				&emsp; &emsp;
				The given syntactic tree was built using the following output of the Native Language API:
			</p>
			<figure typeOf="sa:image" class="ignore-margins">
                <img src="../ArchitectureAndDesign/google-nlp-output-example.png" alt="Google NLP Output example" style="width: 60%">
                <figcaption style="text-align: center;">Fig. 4: Google NLP - output example</figcaption>
            </figure>

            <h3>4.1 Optional Preprocessing: <em>Speech recognition</em> </h3>
            <p>&emsp; &emsp;
                A nice bonus would be to have speech recognition capabilities, meaning that user will be able
                to use his voice in order to <em>type</em> his request.

                In order to do this, we will have to:
            </p>
            <ol>
                <li>
                   Let the user record his voice and save it in cookies or browser storage;
                </li>
                <li>
                    Send the recording to <a href="https://cloud.google.com/speech-to-text">Google Cloud Speech-To-Text</a> service;
                 </li>
                 <li>
                     Use the text returned as the text <em>typed</em> by our user in incoming steps;
                 </li>
            </ol>
        </section>
        <section>
            <h2>5. Rest API</h2>
            <p> &emsp; &emsp;
                The following routes will be <em>necessary but not sufficient</em> for our project:
            </p>
            <ul>
                <li>
                    <b>POST /apis</b> - creates a new Api entry in the database.
                </li>
                <li>
                    <b>GET /apis/{id}</b> - returns all data about the api with the given <em>id</em>. This endpoint will be used more internally.
                </li>
                <li>
                    <b>GET /apis/specifications</b> - lists all stored api specifications. By specification, we mean all the data necessary to display
                    the api in our frontend app: api's internal id, api's public url, api's OpenApi specification url and information about how we should
                    authenticate to the respective api (ApiKey, Oauth2 or no authentication needed)
                </li>
                <li>
                    <b>POST /apis/:id/nlp-to-rest </b> - Translate a command given in natural language into a valid REST request. The natural language text
                    will represent the post's body. This text will be processed as described under <em>4. Natural Language Processing</em> with the help of
                    <a href="https://cloud.google.com/natural-language">Google's Natural Language Processing API</a>. The api will respond with all the elements
                    needed for the client application to create a valid REST request: <em>route</em>, <em>body</em>, <em>Rest verb</em> and <em>parameters</em>.
                </li>
            </ul>
            <p> &emsp; &emsp;
                More detail can be found in our <a href="https://github.com/Kropius/WADe-project/blob/main/documentation/OpenApi/openapi.yaml">OpenAPI Specification</a>.
                Please use <a href="https://editor.swagger.io/">Swagger editor</a>  to read more easly.
            </p>
        </section>
        <section>
            <h2>6. Front-end</h2>
            <p> &emsp; &emsp; The use will interact with a single-page application(SPA), built with React or Angular. </p>
            <figure typeOf="sa:image" class="ignore-margins">
                <img src="../ArchitectureAndDesign/rat-frontend-highlighted.png" alt="Frontend Design">
                <figcaption style="text-align: center;">Fig. 2: Front-end concept</figcaption>
            </figure>
            <p>&emsp; &emsp;
                The design above is more of a guideline and might not be replicated perfectly. Highlited we have short explanations for each ui element
            and how it is going to interact with our API. The SwaggerUI component will be created by using <a href="https://www.npmjs.com/package/angular-swagger-ui">angular-swagger-ui</a>.
            </p>

        </section>
        <section>
            <h2>7. Bibliography</h2>
            <ol>
				<li> <a href="https://cloud.google.com/natural-language/docs/basics">Google Cloud - Natural Language API</a> </li>
				<li> <a href="https://en.wikipedia.org/wiki/Word2vec">Word2Vec - Word Association tool</a> </li>
				<li> <a href="https://arxiv.org/pdf/2007.15280.pdf">PHOTON: A Robust Cross-Domain Text-to-SQL System - Jichuan Zeng, Xi Victoria Lin,
				Caiming Xiong, Richard Socher, Michael R. Lyu, Irwin King, Steven C.H. Hoi</a> </li>
				<li> <a href="https://cloud.google.com/api-gateway/docs">Google Cloud - API Gateway </a> </li>
				<li> <a href="https://cloud.google.com/functions#section-4">Google Cloud Functions</a> </li>
				<li> <a href="https://cloud.google.com/storage#section-4">Google Cloud Storage</a> </li>
				<li> <a href="https://firebase.google.com/products/firestore">Cloud Firestore</a> </li>
				<li> <a href="https://cloud.google.com/speech-to-text#section-6">Google Cloud - Speech to Text</a> </li>
			</ol>
        </section>

    </article>
</body>

</html>